{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d204ce5",
   "metadata": {},
   "source": [
    "## Enhancement 5: Choose a new dataset from the list below. Search the Internet and download your chosen dataset (many of them could be available on kaggle). Adapt your model to your dataset. Train your model and record your results.\n",
    "\n",
    "   * cancer_dataset          - Breast cancer dataset.\n",
    "   * crab_dataset            - Crab gender dataset.\n",
    "   * glass_dataset           - Glass chemical dataset.\n",
    "   * iris_dataset            - Iris flower dataset.\n",
    "   * ovarian_dataset         - Ovarian cancer dataset.\n",
    "   * thyroid_dataset         - Thyroid function dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeeeeea",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed753ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c993ae5",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d27675db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ead43f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cancer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed1724b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=cancer_dataset.data, columns=cancer_dataset.feature_names)\n",
    "df['target'] = cancer_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f5de469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it looks good\n",
    "df.head()\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69e8266d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many features?\n",
    "# WOW!\n",
    "len(df.columns) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2036f641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 means malignant\n",
    "# 1 means benign\n",
    "# @$@ switch these\n",
    "df['target'].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1585657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3848d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data so that each feature has a mean of 0 and a std of 1\n",
    "labels = df['target']\n",
    "# @$@ there is a better way\n",
    "# if vals too big. -> maybe each col normailzed seperatly\n",
    "df = (df - df.mean()) / df.std()\n",
    "df['target'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c555abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5451a6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.096100</td>\n",
       "      <td>-2.071512</td>\n",
       "      <td>1.268817</td>\n",
       "      <td>0.983510</td>\n",
       "      <td>1.567087</td>\n",
       "      <td>3.280628</td>\n",
       "      <td>2.650542</td>\n",
       "      <td>2.530249</td>\n",
       "      <td>2.215566</td>\n",
       "      <td>2.253764</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.358098</td>\n",
       "      <td>2.301575</td>\n",
       "      <td>1.999478</td>\n",
       "      <td>1.306537</td>\n",
       "      <td>2.614365</td>\n",
       "      <td>2.107672</td>\n",
       "      <td>2.294058</td>\n",
       "      <td>2.748204</td>\n",
       "      <td>1.935312</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.828212</td>\n",
       "      <td>-0.353322</td>\n",
       "      <td>1.684473</td>\n",
       "      <td>1.907030</td>\n",
       "      <td>-0.826235</td>\n",
       "      <td>-0.486643</td>\n",
       "      <td>-0.023825</td>\n",
       "      <td>0.547662</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>-0.867889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368879</td>\n",
       "      <td>1.533776</td>\n",
       "      <td>1.888827</td>\n",
       "      <td>-0.375282</td>\n",
       "      <td>-0.430066</td>\n",
       "      <td>-0.146620</td>\n",
       "      <td>1.086129</td>\n",
       "      <td>-0.243675</td>\n",
       "      <td>0.280943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.578499</td>\n",
       "      <td>0.455786</td>\n",
       "      <td>1.565126</td>\n",
       "      <td>1.557513</td>\n",
       "      <td>0.941382</td>\n",
       "      <td>1.052000</td>\n",
       "      <td>1.362280</td>\n",
       "      <td>2.035440</td>\n",
       "      <td>0.938859</td>\n",
       "      <td>-0.397658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023953</td>\n",
       "      <td>1.346291</td>\n",
       "      <td>1.455004</td>\n",
       "      <td>0.526944</td>\n",
       "      <td>1.081980</td>\n",
       "      <td>0.854222</td>\n",
       "      <td>1.953282</td>\n",
       "      <td>1.151242</td>\n",
       "      <td>0.201214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768233</td>\n",
       "      <td>0.253509</td>\n",
       "      <td>-0.592166</td>\n",
       "      <td>-0.763792</td>\n",
       "      <td>3.280667</td>\n",
       "      <td>3.399917</td>\n",
       "      <td>1.914213</td>\n",
       "      <td>1.450431</td>\n",
       "      <td>2.864862</td>\n",
       "      <td>4.906602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>-0.249720</td>\n",
       "      <td>-0.549538</td>\n",
       "      <td>3.391291</td>\n",
       "      <td>3.889975</td>\n",
       "      <td>1.987839</td>\n",
       "      <td>2.173873</td>\n",
       "      <td>6.040726</td>\n",
       "      <td>4.930672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.748758</td>\n",
       "      <td>-1.150804</td>\n",
       "      <td>1.775011</td>\n",
       "      <td>1.824624</td>\n",
       "      <td>0.280125</td>\n",
       "      <td>0.538866</td>\n",
       "      <td>1.369806</td>\n",
       "      <td>1.427237</td>\n",
       "      <td>-0.009552</td>\n",
       "      <td>-0.561956</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.465481</td>\n",
       "      <td>1.337363</td>\n",
       "      <td>1.219651</td>\n",
       "      <td>0.220362</td>\n",
       "      <td>-0.313119</td>\n",
       "      <td>0.612640</td>\n",
       "      <td>0.728618</td>\n",
       "      <td>-0.867590</td>\n",
       "      <td>-0.396751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     1.096100     -2.071512        1.268817   0.983510         1.567087   \n",
       "1     1.828212     -0.353322        1.684473   1.907030        -0.826235   \n",
       "2     1.578499      0.455786        1.565126   1.557513         0.941382   \n",
       "3    -0.768233      0.253509       -0.592166  -0.763792         3.280667   \n",
       "4     1.748758     -1.150804        1.775011   1.824624         0.280125   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          3.280628        2.650542             2.530249       2.215566   \n",
       "1         -0.486643       -0.023825             0.547662       0.001391   \n",
       "2          1.052000        1.362280             2.035440       0.938859   \n",
       "3          3.399917        1.914213             1.450431       2.864862   \n",
       "4          0.538866        1.369806             1.427237      -0.009552   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                2.253764  ...      -1.358098         2.301575    1.999478   \n",
       "1               -0.867889  ...      -0.368879         1.533776    1.888827   \n",
       "2               -0.397658  ...      -0.023953         1.346291    1.455004   \n",
       "3                4.906602  ...       0.133866        -0.249720   -0.549538   \n",
       "4               -0.561956  ...      -1.465481         1.337363    1.219651   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          1.306537           2.614365         2.107672              2.294058   \n",
       "1         -0.375282          -0.430066        -0.146620              1.086129   \n",
       "2          0.526944           1.081980         0.854222              1.953282   \n",
       "3          3.391291           3.889975         1.987839              2.173873   \n",
       "4          0.220362          -0.313119         0.612640              0.728618   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        2.748204                 1.935312       0  \n",
       "1       -0.243675                 0.280943       0  \n",
       "2        1.151242                 0.201214       0  \n",
       "3        6.040726                 4.930672       0  \n",
       "4       -0.867590                -0.396751       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3ad9262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.142575e-15</td>\n",
       "      <td>-6.558316e-15</td>\n",
       "      <td>-7.012551e-16</td>\n",
       "      <td>-8.339355e-16</td>\n",
       "      <td>6.083788e-15</td>\n",
       "      <td>-1.081346e-15</td>\n",
       "      <td>-3.703345e-16</td>\n",
       "      <td>9.935423e-16</td>\n",
       "      <td>-1.888550e-15</td>\n",
       "      <td>-1.424363e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.761138e-15</td>\n",
       "      <td>-1.214416e-15</td>\n",
       "      <td>5.919889e-16</td>\n",
       "      <td>-5.036783e-15</td>\n",
       "      <td>-2.118204e-15</td>\n",
       "      <td>6.899382e-16</td>\n",
       "      <td>-1.732650e-16</td>\n",
       "      <td>-2.454417e-15</td>\n",
       "      <td>2.438979e-15</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.027864e+00</td>\n",
       "      <td>-2.227289e+00</td>\n",
       "      <td>-1.982759e+00</td>\n",
       "      <td>-1.453164e+00</td>\n",
       "      <td>-3.109349e+00</td>\n",
       "      <td>-1.608721e+00</td>\n",
       "      <td>-1.113893e+00</td>\n",
       "      <td>-1.260710e+00</td>\n",
       "      <td>-2.741705e+00</td>\n",
       "      <td>-1.818265e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.222039e+00</td>\n",
       "      <td>-1.691872e+00</td>\n",
       "      <td>-1.221348e+00</td>\n",
       "      <td>-2.680337e+00</td>\n",
       "      <td>-1.442609e+00</td>\n",
       "      <td>-1.304683e+00</td>\n",
       "      <td>-1.743529e+00</td>\n",
       "      <td>-2.159060e+00</td>\n",
       "      <td>-1.600431e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.887793e-01</td>\n",
       "      <td>-7.253249e-01</td>\n",
       "      <td>-6.913472e-01</td>\n",
       "      <td>-6.666089e-01</td>\n",
       "      <td>-7.103378e-01</td>\n",
       "      <td>-7.464292e-01</td>\n",
       "      <td>-7.430941e-01</td>\n",
       "      <td>-7.372951e-01</td>\n",
       "      <td>-7.026215e-01</td>\n",
       "      <td>-7.220040e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.479711e-01</td>\n",
       "      <td>-6.889721e-01</td>\n",
       "      <td>-6.415713e-01</td>\n",
       "      <td>-6.906227e-01</td>\n",
       "      <td>-6.804845e-01</td>\n",
       "      <td>-7.558491e-01</td>\n",
       "      <td>-7.557349e-01</td>\n",
       "      <td>-6.412994e-01</td>\n",
       "      <td>-6.913035e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.148925e-01</td>\n",
       "      <td>-1.045442e-01</td>\n",
       "      <td>-2.357726e-01</td>\n",
       "      <td>-2.949274e-01</td>\n",
       "      <td>-3.486040e-02</td>\n",
       "      <td>-2.217454e-01</td>\n",
       "      <td>-3.419391e-01</td>\n",
       "      <td>-3.973715e-01</td>\n",
       "      <td>-7.156354e-02</td>\n",
       "      <td>-1.781226e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.347738e-02</td>\n",
       "      <td>-2.857288e-01</td>\n",
       "      <td>-3.408813e-01</td>\n",
       "      <td>-4.680159e-02</td>\n",
       "      <td>-2.692639e-01</td>\n",
       "      <td>-2.180402e-01</td>\n",
       "      <td>-2.232725e-01</td>\n",
       "      <td>-1.272975e-01</td>\n",
       "      <td>-2.162538e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.689800e-01</td>\n",
       "      <td>5.836621e-01</td>\n",
       "      <td>4.992377e-01</td>\n",
       "      <td>3.631877e-01</td>\n",
       "      <td>6.356397e-01</td>\n",
       "      <td>4.934227e-01</td>\n",
       "      <td>5.255994e-01</td>\n",
       "      <td>6.463664e-01</td>\n",
       "      <td>5.303125e-01</td>\n",
       "      <td>4.705693e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.577623e-01</td>\n",
       "      <td>5.398040e-01</td>\n",
       "      <td>3.572747e-01</td>\n",
       "      <td>5.970195e-01</td>\n",
       "      <td>5.391944e-01</td>\n",
       "      <td>5.306742e-01</td>\n",
       "      <td>7.118836e-01</td>\n",
       "      <td>4.497425e-01</td>\n",
       "      <td>4.503661e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.967796e+00</td>\n",
       "      <td>4.647799e+00</td>\n",
       "      <td>3.972634e+00</td>\n",
       "      <td>5.245913e+00</td>\n",
       "      <td>4.766717e+00</td>\n",
       "      <td>4.564409e+00</td>\n",
       "      <td>4.239858e+00</td>\n",
       "      <td>3.924477e+00</td>\n",
       "      <td>4.480808e+00</td>\n",
       "      <td>4.906602e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.882489e+00</td>\n",
       "      <td>4.283568e+00</td>\n",
       "      <td>5.924959e+00</td>\n",
       "      <td>3.951897e+00</td>\n",
       "      <td>5.108382e+00</td>\n",
       "      <td>4.696536e+00</td>\n",
       "      <td>2.683516e+00</td>\n",
       "      <td>6.040726e+00</td>\n",
       "      <td>6.840837e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean radius  mean texture  mean perimeter     mean area  \\\n",
       "count  5.690000e+02  5.690000e+02    5.690000e+02  5.690000e+02   \n",
       "mean  -3.142575e-15 -6.558316e-15   -7.012551e-16 -8.339355e-16   \n",
       "std    1.000000e+00  1.000000e+00    1.000000e+00  1.000000e+00   \n",
       "min   -2.027864e+00 -2.227289e+00   -1.982759e+00 -1.453164e+00   \n",
       "25%   -6.887793e-01 -7.253249e-01   -6.913472e-01 -6.666089e-01   \n",
       "50%   -2.148925e-01 -1.045442e-01   -2.357726e-01 -2.949274e-01   \n",
       "75%    4.689800e-01  5.836621e-01    4.992377e-01  3.631877e-01   \n",
       "max    3.967796e+00  4.647799e+00    3.972634e+00  5.245913e+00   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count     5.690000e+02      5.690000e+02    5.690000e+02         5.690000e+02   \n",
       "mean      6.083788e-15     -1.081346e-15   -3.703345e-16         9.935423e-16   \n",
       "std       1.000000e+00      1.000000e+00    1.000000e+00         1.000000e+00   \n",
       "min      -3.109349e+00     -1.608721e+00   -1.113893e+00        -1.260710e+00   \n",
       "25%      -7.103378e-01     -7.464292e-01   -7.430941e-01        -7.372951e-01   \n",
       "50%      -3.486040e-02     -2.217454e-01   -3.419391e-01        -3.973715e-01   \n",
       "75%       6.356397e-01      4.934227e-01    5.255994e-01         6.463664e-01   \n",
       "max       4.766717e+00      4.564409e+00    4.239858e+00         3.924477e+00   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count   5.690000e+02            5.690000e+02  ...   5.690000e+02   \n",
       "mean   -1.888550e-15           -1.424363e-15  ...   1.761138e-15   \n",
       "std     1.000000e+00            1.000000e+00  ...   1.000000e+00   \n",
       "min    -2.741705e+00           -1.818265e+00  ...  -2.222039e+00   \n",
       "25%    -7.026215e-01           -7.220040e-01  ...  -7.479711e-01   \n",
       "50%    -7.156354e-02           -1.781226e-01  ...  -4.347738e-02   \n",
       "75%     5.303125e-01            4.705693e-01  ...   6.577623e-01   \n",
       "max     4.480808e+00            4.906602e+00  ...   3.882489e+00   \n",
       "\n",
       "       worst perimeter    worst area  worst smoothness  worst compactness  \\\n",
       "count     5.690000e+02  5.690000e+02      5.690000e+02       5.690000e+02   \n",
       "mean     -1.214416e-15  5.919889e-16     -5.036783e-15      -2.118204e-15   \n",
       "std       1.000000e+00  1.000000e+00      1.000000e+00       1.000000e+00   \n",
       "min      -1.691872e+00 -1.221348e+00     -2.680337e+00      -1.442609e+00   \n",
       "25%      -6.889721e-01 -6.415713e-01     -6.906227e-01      -6.804845e-01   \n",
       "50%      -2.857288e-01 -3.408813e-01     -4.680159e-02      -2.692639e-01   \n",
       "75%       5.398040e-01  3.572747e-01      5.970195e-01       5.391944e-01   \n",
       "max       4.283568e+00  5.924959e+00      3.951897e+00       5.108382e+00   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count     5.690000e+02          5.690000e+02    5.690000e+02   \n",
       "mean      6.899382e-16         -1.732650e-16   -2.454417e-15   \n",
       "std       1.000000e+00          1.000000e+00    1.000000e+00   \n",
       "min      -1.304683e+00         -1.743529e+00   -2.159060e+00   \n",
       "25%      -7.558491e-01         -7.557349e-01   -6.412994e-01   \n",
       "50%      -2.180402e-01         -2.232725e-01   -1.272975e-01   \n",
       "75%       5.306742e-01          7.118836e-01    4.497425e-01   \n",
       "max       4.696536e+00          2.683516e+00    6.040726e+00   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count             5.690000e+02  569.000000  \n",
       "mean              2.438979e-15    0.627417  \n",
       "std               1.000000e+00    0.483918  \n",
       "min              -1.600431e+00    0.000000  \n",
       "25%              -6.913035e-01    0.000000  \n",
       "50%              -2.162538e-01    1.000000  \n",
       "75%               4.503661e-01    1.000000  \n",
       "max               6.840837e+00    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sumamry statistics of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd17b67",
   "metadata": {},
   "source": [
    "## Load this dataset for training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c2d5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset class\n",
    "# inherit the Dataset class and create a new class CancerDataset\n",
    "class CancerDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Iterate through rows of the DataFrame\n",
    "        for _, row in df.iterrows():\n",
    "            # Append features for each row except the 'target' column\n",
    "            self.features.append(row.drop('target').tolist())\n",
    "            # Append label for each row\n",
    "            self.labels.append(row['target'])\n",
    "    \n",
    "    # set length to reaturn number of rows\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    # get a sample in the form of a dictionary (features and labels) given its index\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        features = self.features[idx]\n",
    "        features = torch.FloatTensor(features)\n",
    "\n",
    "        labels = torch.tensor(self.labels[idx], dtype = torch.long)\n",
    "\n",
    "        return {'labels': labels, 'features': features}\n",
    "\n",
    "# instanciate a CancerDataset object based off of data_df\n",
    "cancer_dataset = CancerDataset(df)\n",
    "# perform a 80, 10, 10 split using the cancer_dataset object\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(cancer_dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "# The dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    # dataset input\n",
    "    train_dataset,\n",
    "    # batches of 4 during training\n",
    "    batch_size = 4,\n",
    "    # don't learn from the order of the dataset!\n",
    "    shuffle = True,\n",
    "    # multy processing. (0 = 1 process to load data)\n",
    "    # how many processes can you do? \n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "#want results without any randomness, therfore shuffle is False for these\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 4, shuffle = False, num_workers = 0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 4, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36fd2d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(0), 'features': tensor([ 1.0961, -2.0715,  1.2688,  0.9835,  1.5671,  3.2806,  2.6505,  2.5302,\n",
      "         2.2156,  2.2538,  2.4875, -0.5648,  2.8305,  2.4854, -0.2138,  1.3157,\n",
      "         0.7234,  0.6602,  1.1477,  0.9063,  1.8850, -1.3581,  2.3016,  1.9995,\n",
      "         1.3065,  2.6144,  2.1077,  2.2941,  2.7482,  1.9353])}\n"
     ]
    }
   ],
   "source": [
    "# peak into the dataset\n",
    "for i in cancer_dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af85b59",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e595fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the device to gpu if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c9042e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines new class named CancerModel, inherits from torch.blah\n",
    "class CancerModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # initialize in the same way the parent class does first\n",
    "        super(CancerModel, self).__init__()\n",
    "        \n",
    "        # create linear layer. 11 inputs 200 outputs?\n",
    "        self.linear1 = torch.nn.Linear(30, 210)                \n",
    "        # creates activation function (What does this do and how does it work @$@)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "        # a second linear layer. Takes in 200 and outputs 6 (one corresponding to each feature)\n",
    "        self.linear2 = torch.nn.Linear(210, 2)              \n",
    "         \n",
    "        # sigmoid activation for binary\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    # defines forward pass of nn\n",
    "    # sends input through the tunnel: lin1 -> act -> line2 -> softmax \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# earlier we set device to cpu or gpu\n",
    "# create this CancerModel object, then move to cpu or gpu\n",
    "cancermodel = CancerModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfd224aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and the loss function and optimizer\n",
    "# we are trying binary cross entropy loss\n",
    "# what is BCE using as inputs\n",
    "    # \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# an optimizer @$@ what does it do? \n",
    "# specify the learning rate\n",
    "optimizer = AdamW(cancermodel.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "deb94b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define the training steps\n",
    "def accuracy(preds, labels):\n",
    "    preds = torch.argmax(preds, dim=1).flatten()\n",
    "    return torch.sum(preds == labels) / len(labels)\n",
    "\n",
    "def train(model, data_loader, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    \n",
    "    # iterate over batches\n",
    "    for d in tqdm(data_loader):\n",
    "        inputs = d['features'].to(device)\n",
    "        #labels = d['labels'].unsqueeze(1).to(device)  # Adjusting the shape of the target tensor\n",
    "        labels = d['labels'].to(device)  # Adjusting the shape of the target tensor\n",
    "\n",
    "        labels = labels.float()  # Cast labels to float32\n",
    "        \n",
    "        # obtaining predictions\n",
    "        outputs = cancermodel(inputs)\n",
    "        preds = (outputs > 0.5).float()  # Convert logits to binary predictions\n",
    "        print(f'target shape:{labels.shape}',f'inputs shape:{outputs.shape}')\n",
    "        # calulate loss and accuracy by comparing predictions to labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = accuracy(preds, labels)  # Use binary accuracy function\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader)\n",
    "\n",
    "\n",
    "# Lets define the testing steps\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    # eval mode activate!\n",
    "    model.eval()\n",
    "    \n",
    "    # iterate over batches (later we will average the huge sum)\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            # extract labels and features from batch and send to cpu/gpu\n",
    "            inputs = d['features'].to(device)\n",
    "            labels = d['labels'].unsqueeze(1).to(device)  # Adjusting the shape of the target tensor\n",
    "            labels = labels.float()  # Convert labels to float32\n",
    "            \n",
    "            # use model to get predictions\n",
    "            outputs = cancermodel(inputs)\n",
    "            \n",
    "            #  get loss and accuracy\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = accuracy(outputs, labels)\n",
    "            \n",
    "            # run a big sum!\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            precision = precision_score(labels.cpu(), outputs.cpu() > 0.5, average='weighted')\n",
    "            recall = recall_score(labels.cpu(), outputs.cpu() > 0.5, average='weighted')\n",
    "            f1 = f1_score(labels.cpu(), outputs.cpu() > 0.5, average='weighted')\n",
    "            epoch_precision += precision\n",
    "            epoch_recall += recall\n",
    "            epoch_f1 += f1\n",
    "\n",
    "    # average big sums by # of epochs\n",
    "    num_batches = len(data_loader)\n",
    "    return (epoch_loss / num_batches, \n",
    "            epoch_acc / num_batches, \n",
    "            epoch_precision / num_batches, \n",
    "            epoch_recall / num_batches,\n",
    "            epoch_f1 / num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5ddfffa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0370452984bb41d584e8c10767ec3f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target shape:torch.Size([4, 1]) inputs shape:torch.Size([4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dansc\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Let's train our model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcancermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     valid_loss, valid_acc, valid_precision, valid_recall, valid_f1 \u001b[38;5;241m=\u001b[39m evaluate(cancermodel, val_dataloader, criterion)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m| Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | Val. Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val. Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | Val. Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val. Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val. F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m |\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget shape:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs shape:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# calulate loss and accuracy by comparing predictions to labels\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(preds, labels)  \u001b[38;5;66;03m# Use binary accuracy function\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# Let's train our model\n",
    "for epoch in range(50):\n",
    "    train_loss, train_acc = train(cancermodel, train_dataloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc, valid_precision, valid_recall, valid_f1 = evaluate(cancermodel, val_dataloader, criterion)\n",
    "\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% | Val. Precision: {valid_precision:.3f} | Val. Recall: {valid_recall:.3f} | Val. F1-score: {valid_f1:.3f} |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2b86b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dansc\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m test_loss, test_acc, test_prec, test_rec, test_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcancermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m| Test. Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test. Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | Test. Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_prec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test. Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_rec\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test. F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m |\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, criterion)\u001b[0m\n\u001b[0;32m     58\u001b[0m outputs \u001b[38;5;241m=\u001b[39m cancermodel(inputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#  get loss and accuracy\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(outputs, labels)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# run a big sum!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "test_loss, test_acc, test_prec, test_rec, test_f1 = evaluate(cancermodel, test_dataloader, criterion)\n",
    "\n",
    "\n",
    "print(f'| Test. Loss: {test_loss:.3f} | Test. Acc: {test_acc*100:.2f}% | Test. Precision: {test_prec:.3f} | Test. Recall: {test_rec:.3f} | Test. F1-score: {test_f1:.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d1721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.resetwarnings()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
